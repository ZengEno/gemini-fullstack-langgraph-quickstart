{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是阿里云百炼大模型平台的相关配置\n",
    "DASHSCOPE_API_KEY='sk-4fcdc14b214041059daa67993312ba7d'\n",
    "DASHSCOPE_BASE_URL='https://dashscope.aliyuncs.com/compatible-mode/v1'\n",
    "\n",
    "# 以下是阿里云开放搜索服务的相关配置\n",
    "ALIYUN_OPENSEARCH_API_KEY='OS-682s52xo4ik96lc4'\n",
    "ALIYUN_OPENSEARCH_HOST='default-128q.platform-cn-shanghai.opensearch.aliyuncs.com'\n",
    "ALIYUN_OPENSEARCH_WORKSPACE_NAME='default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Generator Result: content='' additional_kwargs={'tool_calls': [{'id': 'call_3a26869f7367412f9bca94', 'function': {'arguments': '{\"query\":[\"What is France\",\"History of France\",\"Culture of France\"],\"rationale\":\"These queries will help us gather information about what France is, including its history and cultural aspects.\"}', 'name': 'SearchQueryList'}, 'type': 'function', 'index': 0}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 227, 'total_tokens': 277, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen-turbo', 'system_fingerprint': None, 'id': 'chatcmpl-d226aae1-3a44-9dbe-837e-4f9c933d8308', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None} id='run--323e1155-f237-48bb-948f-6c2d3ef6464f-0' tool_calls=[{'name': 'SearchQueryList', 'args': {'query': ['What is France', 'History of France', 'Culture of France'], 'rationale': 'These queries will help us gather information about what France is, including its history and cultural aspects.'}, 'id': 'call_3a26869f7367412f9bca94', 'type': 'tool_call'}] usage_metadata={'input_tokens': 227, 'output_tokens': 50, 'total_tokens': 277, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "\n",
      "\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class SearchQueryList(BaseModel):\n",
    "    query: List[str] = Field(\n",
    "        description=\"A list of search queries to be used for web research.\"\n",
    "    )\n",
    "    rationale: str = Field(\n",
    "        description=\"A brief explanation of why these queries are relevant to the research topic.\"\n",
    "    )\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"qwen-turbo\", temperature=1.0, max_retries=2, api_key=DASHSCOPE_API_KEY, base_url=DASHSCOPE_BASE_URL)\n",
    "\n",
    "message_to_llm = \"Generate 3 search queries for the topic: What is France?\"\n",
    "\n",
    "llm_with_tool = llm.bind_tools([SearchQueryList])\n",
    "response_llm_with_tool = llm_with_tool.invoke(message_to_llm)\n",
    "print(f\"Query Generator Result: {response_llm_with_tool}\\n\\n\")\n",
    "print(type(response_llm_with_tool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Generator Result: content='' additional_kwargs={'tool_calls': [{'id': 'call_1706c70a74994f4ab494eb', 'function': {'arguments': '{\"is_sufficient\": true, \"knowledge_gap\": \"\", \"follow_up_queries\": []}', 'name': 'Reflection'}, 'type': 'function', 'index': 0}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 269, 'total_tokens': 298, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen-turbo', 'system_fingerprint': None, 'id': 'chatcmpl-2624e4b2-0125-957c-81f2-338f105ceef3', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None} id='run--e6f75f21-ac6f-44c5-9125-5c89c9e530ad-0' tool_calls=[{'name': 'Reflection', 'args': {'is_sufficient': True, 'knowledge_gap': '', 'follow_up_queries': []}, 'id': 'call_1706c70a74994f4ab494eb', 'type': 'tool_call'}] usage_metadata={'input_tokens': 269, 'output_tokens': 29, 'total_tokens': 298, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "\n",
      "\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Reflection(BaseModel):\n",
    "    is_sufficient: bool = Field(\n",
    "        description=\"Whether the provided summaries are sufficient to answer the user's question.\"\n",
    "    )\n",
    "    knowledge_gap: str = Field(\n",
    "        description=\"A description of what information is missing or needs clarification.\"\n",
    "    )\n",
    "    follow_up_queries: List[str] = Field(\n",
    "        description=\"A list of follow-up queries to address the knowledge gap.\"\n",
    "    )\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"qwen-turbo\", temperature=1.0, max_retries=2, api_key=DASHSCOPE_API_KEY, base_url=DASHSCOPE_BASE_URL)\n",
    "\n",
    "message_to_llm = \"this is a test, you need to use the tool to generate the reflection. Just put anything you think is correct in the parameters.\"\n",
    "\n",
    "llm_with_tool = llm.bind_tools([Reflection])\n",
    "response_llm_with_tool = llm_with_tool.invoke(message_to_llm)\n",
    "print(f\"Query Generator Result: {response_llm_with_tool}\\n\\n\")\n",
    "print(type(response_llm_with_tool))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
